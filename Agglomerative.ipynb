{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'date'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\pandas\\core\\indexes\\base.py\u001b[0m in \u001b[0;36mget_loc\u001b[1;34m(self, key, method, tolerance)\u001b[0m\n\u001b[0;32m   2656\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2657\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2658\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'date'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-6-077a127d0b2d>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     28\u001b[0m \u001b[0mlatlon\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'lon'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'lat'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     29\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 30\u001b[1;33m \u001b[0mdates\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'date'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     31\u001b[0m     \u001b[1;31m#empty data frame for storing clusters\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     32\u001b[0m \u001b[0mclusterData\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mrecheader\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   2925\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnlevels\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2926\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_getitem_multilevel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2927\u001b[1;33m             \u001b[0mindexer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2928\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mis_integer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2929\u001b[0m                 \u001b[0mindexer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mindexer\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\pandas\\core\\indexes\\base.py\u001b[0m in \u001b[0;36mget_loc\u001b[1;34m(self, key, method, tolerance)\u001b[0m\n\u001b[0;32m   2657\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2658\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2659\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_maybe_cast_indexer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2660\u001b[0m         \u001b[0mindexer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_indexer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmethod\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtolerance\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtolerance\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2661\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mindexer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m1\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mindexer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msize\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'date'"
     ]
    }
   ],
   "source": [
    "from sklearn.cluster import AgglomerativeClustering\n",
    "from shapely.geometry import MultiPoint\n",
    "\n",
    "import pandas as pd\n",
    "import datetime\n",
    "from dateutil import parser\n",
    "import numpy as np\n",
    "import geopandas as gpd\n",
    "from dateutil import parser\n",
    "\n",
    "datafile='C:\\File\\GISFile.csv'\n",
    "data=pd.read_csv(datafile)\n",
    "data.Date=[parser.parse(t).date() for t in data.Date]\n",
    "start_date=None\n",
    "if start_date is None:\n",
    "        start_date=np.min(data.Date.values)\n",
    "        recheader=['id','centroid_x','centroid_y']\n",
    "end_date=datetime.datetime.now().date()\n",
    "datevals=[start_date+datetime.timedelta(days=i) for i in range((end_date-start_date).days+1)]\n",
    "recheader.extend(datevals)\n",
    "gpframe=gpd.GeoDataFrame(data,geometry=gpd.points_from_xy(data.lon, data.lat))\n",
    "gpframe.crs={'init': 'epsg:4326'}\n",
    "gpframe=gpframe.to_crs({'init': 'epsg:26917'})\n",
    "data['x']=[geom.x for geom in gpframe.geometry]\n",
    "data['y']=[geom.y for geom in gpframe.geometry]\n",
    "data=data.drop(columns=['geometry'])\n",
    "xy=data[['x','y']].values\n",
    "latlon=data[['lon','lat']].values\n",
    "   \n",
    "dates=data['date'].values\n",
    "    #empty data frame for storing clusters\n",
    "clusterData=pd.DataFrame(columns=recheader)\n",
    "    #run agglomerative clustering algorithm\n",
    "clustering = AgglomerativeClustering(n_clusters=None,linkage='single',distance_threshold=maxdistance,compute_full_tree=True).fit(xy)\n",
    "    #cluster labels\n",
    "labels = clustering.labels_\n",
    "total_clusters = len(set(labels))\n",
    "k=0\n",
    "geometries=[]\n",
    "ids=[]\n",
    "minneighbors=10\n",
    "maxdistance=1000\n",
    "    \n",
    "for i in range(total_clusters):\n",
    "        ltln=latlon[labels==i]\n",
    "        date=dates[labels==i]\n",
    "        prjpoints=xy[labels==i]\n",
    "        if len(ltln)!=0 and len(ltln)>=minneighbors:\n",
    "            tdframe=pd.DataFrame(columns=['date'])\n",
    "            tdframe.date=datevals\n",
    "            newdframe=pd.DataFrame(columns=['date','counts'])\n",
    "            #aggregate counts based on date\n",
    "            unique, counts = np.unique(date, return_counts=True)\n",
    "            newdframe.date=unique\n",
    "            newdframe.counts=counts\n",
    "            tdframe=tdframe.merge(newdframe,on='date',how='outer')\n",
    "            tdframe=tdframe.fillna(0)\n",
    "            #cumulative sum for the dates\n",
    "            cnts=np.cumsum(tdframe.counts.values)\n",
    "            #set zero for total neighbors\n",
    "            cnts[cnts<minneighbors]=0\n",
    "            tdframe.counts=cnts\n",
    "            #for generating centroids\n",
    "            geom=MultiPoint(ltln)\n",
    "            dat=[k,geom.centroid.x,geom.centroid.y]\n",
    "            ids.append(k)\n",
    "            geom_proj=MultiPoint(prjpoints)\n",
    "            #convex hulls based on all members\n",
    "            geom_hull=geom_proj.convex_hull\n",
    "            if geom_hull.geom_type!='Polygon':\n",
    "                geom_hull=geom_hull.buffer(maxdistance)\n",
    "            geometries.append(geom_hull)\n",
    "            dat.extend(tdframe.counts.values.tolist())\n",
    "            clusterData.loc[len(clusterData)]=dat\n",
    "            k+=1\n",
    "    #write cluster data to csv file\n",
    "            clusterData.to_csv(datafile.replace('.csv','')+\"_centroids__\"+str(maxdistance)+\"_\"+str(minneighbors)+'.csv',index=False)\n",
    "    #write cluster shapes to CSV\n",
    "            gdf = gpd.GeoDataFrame(pd.DataFrame(ids,columns=['id']), geometry=geometries,crs={'init': 'epsg:26917'})\n",
    "            gdf.to_file(datafile.replace('.csv','')+\"_shapes__\"+str(maxdistance)+\"_\"+str(minneighbors)+'.shp') \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import AgglomerativeClustering\n",
    "from shapely.geometry import MultiPoint\n",
    "\n",
    "import pandas as pd\n",
    "import datetime\n",
    "from dateutil import parser\n",
    "import numpy as np\n",
    "import geopandas as gpd\n",
    "from dateutil import parser\n",
    "\n",
    "datafile='C:\\File\\GISFile.csv'\n",
    "data=pd.read_csv(datafile)\n",
    "data.Date=[parser.parse(t).date() for t in data.Date]\n",
    "start_date=None\n",
    "if start_date is None:\n",
    "        start_date=np.min(data.Date.values)\n",
    "        recheader=['id','centroid_x','centroid_y']\n",
    "end_date=datetime.datetime.now().date()\n",
    "datevals=[start_date+datetime.timedelta(days=i) for i in range((end_date-start_date).days+1)]\n",
    "recheader.extend(datevals)\n",
    "gpframe=gpd.GeoDataFrame(data,geometry=gpd.points_from_xy(data.lon, data.lat))\n",
    "gpframe.crs={'init': 'epsg:4326'}\n",
    "gpframe=gpframe.to_crs({'init': 'epsg:26917'})\n",
    "data['x']=[geom.x for geom in gpframe.geometry]\n",
    "data['y']=[geom.y for geom in gpframe.geometry]\n",
    "data=data.drop(columns=['geometry'])\n",
    "xy=data[['x','y']].values\n",
    "latlon=data[['lon','lat']].values\n",
    "   \n",
    "dates=data['Date'].values\n",
    "minneighbors=10\n",
    "maxdistance=1000\n",
    "    #empty data frame for storing clusters\n",
    "clusterData=pd.DataFrame(columns=recheader)\n",
    "    #run agglomerative clustering algorithm\n",
    "clustering = AgglomerativeClustering(n_clusters=None,linkage='single',distance_threshold=maxdistance,compute_full_tree=True).fit(xy)\n",
    "    #cluster labels\n",
    "labels = clustering.labels_\n",
    "total_clusters = len(set(labels))\n",
    "k=0\n",
    "geometries=[]\n",
    "ids=[]\n",
    "for i in range(total_clusters):\n",
    "        ltln=latlon[labels==i]\n",
    "        date=dates[labels==i]\n",
    "        prjpoints=xy[labels==i]\n",
    "        if len(ltln)!=0 and len(ltln)>=minneighbors:\n",
    "            tdframe=pd.DataFrame(columns=['date'])\n",
    "            tdframe.date=datevals\n",
    "            newdframe=pd.DataFrame(columns=['date','counts'])\n",
    "           \n",
    "            unique, counts = np.unique(date, return_counts=True)\n",
    "            newdframe.date=unique\n",
    "            newdframe.counts=counts\n",
    "            tdframe=tdframe.merge(newdframe,on='date',how='outer')\n",
    "            tdframe=tdframe.fillna(0)\n",
    "          \n",
    "            cnts=np.cumsum(tdframe.counts.values)\n",
    "          \n",
    "            cnts[cnts<minneighbors]=0\n",
    "            tdframe.counts=cnts\n",
    "  \n",
    "            geom=MultiPoint(ltln)\n",
    "            dat=[k,geom.centroid.x,geom.centroid.y]\n",
    "            ids.append(k)\n",
    "            geom_proj=MultiPoint(prjpoints)\n",
    "         \n",
    "            geom_hull=geom_proj.convex_hull\n",
    "            if geom_hull.geom_type!='Polygon':\n",
    "                geom_hull=geom_hull.buffer(maxdistance)\n",
    "            geometries.append(geom_hull)\n",
    "            dat.extend(tdframe.counts.values.tolist())\n",
    "            clusterData.loc[len(clusterData)]=dat\n",
    "            k+=1\n",
    "  \n",
    "            clusterData.to_csv(datafile.replace('.csv','')+\"_centroids__\"+str(maxdistance)+\"_\"+str(minneighbors)+'.csv',index=False)\n",
    "  \n",
    "            gdf = gpd.GeoDataFrame(pd.DataFrame(ids,columns=['id']), geometry=geometries,crs={'init': 'epsg:26917'})\n",
    "            gdf.to_file(datafile.replace('.csv','')+\"_shapes__\"+str(maxdistance)+\"_\"+str(minneighbors)+'.shp') \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
